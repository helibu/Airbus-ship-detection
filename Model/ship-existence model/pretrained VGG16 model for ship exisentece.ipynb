{
  "cells": [
    {
      "metadata": {
        "_uuid": "aa8401d73c7a19e1a43fdd6a992ea9dcb60039a2"
      },
      "cell_type": "markdown",
      "source": "# Overview\nUse pre-trained neural network to predict the existence and use it as the backend of the U-net model to do segmentation.\n### Models used\nWe start from navie CNN, to models in keras.applications lib. We have tried navie CNN, VGG16, InceptionV3, Inception ResNet V2, Xception, DenseNet169, DenseNet121, ResNet50.\n\nThe models were trained on 15000 (80% train, 20% validation) images for 30 epoches. The best result is with ResNet50, with batch size 64, learning rate 1e-4, dropout 0.2. The binary accuray is about 92% for both training set and validation set.\n"
    },
    {
      "metadata": {
        "_uuid": "a6cd9d5ad61ffe3b8858769f20a5f9493f024a56"
      },
      "cell_type": "markdown",
      "source": "### Model Parameters\nTried several parameters, the selected one are the best we know."
    },
    {
      "metadata": {
        "_uuid": "ccf73e54776e06ec6d9260e9cdddda3f2b384741"
      },
      "cell_type": "markdown",
      "source": "### Import library"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "301a5d939c566d1487a049bb2554d09b592b18b1"
      },
      "cell_type": "code",
      "source": "import os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\nfrom skimage.segmentation import mark_boundaries\nfrom skimage.util.montage import montage2d as montage\nfrom sklearn.model_selection import train_test_split\nmontage_rgb = lambda x: np.stack([montage(x[:, :, :, i]) for i in range(x.shape[3])], -1)\nship_dir = '../input'\ntrain_image_dir = os.path.join(ship_dir, 'train_v2')\ntest_image_dir = os.path.join(ship_dir, 'test_v2')\nimport gc; gc.enable() # memory is tight\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1b95c25b61cb6404c9cf70dea1d9147609b95582"
      },
      "cell_type": "markdown",
      "source": "### parameters setting"
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "GAUSSIAN_NOISE = 0.1\nUPSAMPLE_MODE = 'SIMPLE'\nVALID_IMG_COUNT = 1000\nMAX_TRAIN_IMAGES = 15000 \nIMG_SIZE = (299, 299) \nBATCH_SIZE = 64 \nDROPOUT = 0.2\nDENSE_COUNT = 128\nLEARN_RATE = 1e-4\nRGB_FLIP = 1 # should rgb be flipped when rendering images",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3ca7119188fbb4c6540d9df55f5833b55435287e"
      },
      "cell_type": "code",
      "source": "masks = pd.read_csv(os.path.join('../input/',\n                                 'train_ship_segmentations_v2.csv'))\nprint(masks.shape[0], 'masks found')\nprint(masks['ImageId'].value_counts().shape[0])\nmasks['path'] = masks['ImageId'].map(lambda x: os.path.join(train_image_dir, x))\nmasks.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "40cb72e241c0c3d8bc245b4e3c663b4a835b0011"
      },
      "cell_type": "markdown",
      "source": "### Split into training and validation groups"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "871720221ac25f7f9408bfe01aeb4ccb95edbd1f"
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split\nmasks['ships'] = masks['EncodedPixels'].map(lambda c_row: 1 if isinstance(c_row, str) else 0)\nunique_img_ids = masks.groupby('ImageId').agg({'ships': 'sum'}).reset_index()\nunique_img_ids['has_ship'] = unique_img_ids['ships'].map(lambda x: 1.0 if x>0 else 0.0)\nunique_img_ids['has_ship_vec'] = unique_img_ids['has_ship'].map(lambda x: [x])\nmasks.drop(['ships'], axis=1, inplace=True)\ntrain_ids, valid_ids = train_test_split(unique_img_ids, \n                 test_size = 0.2, \n                 stratify = unique_img_ids['ships'])\ntrain_df = pd.merge(masks, train_ids)\nvalid_df = pd.merge(masks, valid_ids)\nprint(train_df.shape[0], 'training masks')\nprint(valid_df.shape[0], 'validation masks')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c21d5bff04bf9180463969ac120379345745ed03"
      },
      "cell_type": "markdown",
      "source": "### Examine Number of Ship Images\nHere we examine how often ships appear and replace the ones without any ships with 0"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fa2154d3621497e7497731e5ef6c6c72f27ad483"
      },
      "cell_type": "code",
      "source": "train_df = train_df.sample(min(MAX_TRAIN_IMAGES, train_df.shape[0])) # limit size of training set (otherwise it takes too long)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7b10155d8bcaa824c3442c5ee0a731295c0ddd32"
      },
      "cell_type": "code",
      "source": "train_df[['ships', 'has_ship']].hist()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a8f65e7942816fb75b687a549dc1d5cc48d00e21"
      },
      "cell_type": "markdown",
      "source": "## Augment Data\nSince the number of images with ships and without ships are not even, we need to generate more data using ImageDataGenerator."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ccbc1747ffb0f2942cc99bc27e4afc3262ba9f94"
      },
      "cell_type": "code",
      "source": "from keras.preprocessing.image import ImageDataGenerator\n#from keras.applications.resnet50 import ResNet50,preprocess_input\nfrom keras.applications.vgg16 import VGG16,preprocess_input\nfrom keras.preprocessing.image import ImageDataGenerator",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "dg_args = dict(featurewise_center = False, \n                  samplewise_center = False,\n                  rotation_range = 45, \n                  width_shift_range = 0.1, \n                  height_shift_range = 0.1, \n                  shear_range = 0.01,\n                  zoom_range = [0.9, 1.25],  \n                  brightness_range = [0.5, 1.5],\n                  horizontal_flip = True, \n                  vertical_flip = True,\n                  fill_mode = 'reflect',\n                   data_format = 'channels_last',\n              preprocessing_function = preprocess_input)\nvalid_args = dict(featurewise_center = False,\n              samplewise_center = False,\n              rotation_range = 45, \n              width_shift_range = 0.1, \n              height_shift_range = 0.1, \n              shear_range = 0.01,\n              zoom_range = [0.9, 1.25],  \n              brightness_range = [0.5, 1.5],\n              horizontal_flip = True, \n              vertical_flip = True,\n              fill_mode = 'reflect',\n               data_format = 'channels_last',\n              preprocessing_function = preprocess_input)\n\ncore_idg = ImageDataGenerator(**dg_args)\nvalid_idg = ImageDataGenerator(**valid_args)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c5cc31e3117fdfa923b2acb1e6542a7007f4f955"
      },
      "cell_type": "code",
      "source": "def flow_from_dataframe(img_data_gen, in_df, path_col, y_col, **dflow_args):\n    base_dir = os.path.dirname(in_df[path_col].values[0])\n    print('## Ignore next message from keras, values are replaced anyways')\n    df_gen = img_data_gen.flow_from_directory(base_dir, \n                                     class_mode = 'sparse',\n                                    **dflow_args)\n    df_gen.filenames = in_df[path_col].values\n    df_gen.classes = np.stack(in_df[y_col].values)\n    df_gen.samples = in_df.shape[0]\n    df_gen.n = in_df.shape[0]\n    df_gen._set_index_array()\n    df_gen.directory = '' # since we have the full path\n    print('Reinserting dataframe: {} images'.format(in_df.shape[0]))\n    return df_gen",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "67136e1743dbbc4e07dba0d69f79231603f31d93"
      },
      "cell_type": "code",
      "source": "train_gen = flow_from_dataframe(core_idg, train_df, \n                             path_col = 'path',\n                            y_col = 'has_ship_vec', \n                            target_size = IMG_SIZE,\n                             color_mode = 'rgb',\n                            batch_size = BATCH_SIZE)\n\n# used a fixed dataset for evaluating the algorithm\nvalid_x, valid_y = next(flow_from_dataframe(valid_idg, \n                               valid_df, \n                             path_col = 'path',\n                            y_col = 'has_ship_vec', \n                            target_size = IMG_SIZE,\n                             color_mode = 'rgb',\n                            batch_size = VALID_IMG_COUNT)) # one big batch\nprint(valid_x.shape, valid_y.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6122ccb9e58bfac6fa5e11c86121e78d9e5151b1"
      },
      "cell_type": "code",
      "source": "t_x, t_y = next(train_gen)\nprint('x', t_x.shape, t_x.dtype, t_x.min(), t_x.max())\nprint('y', t_y.shape, t_y.dtype, t_y.min(), t_y.max())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ba08494eb9736ec3556b7c879143cdcdea89febf"
      },
      "cell_type": "markdown",
      "source": "## Build a Model\nWe build the pre-trained top model and then use a global-max-pooling."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2687377309d3cbbab1197f4eccd2b50ab996f5a6"
      },
      "cell_type": "code",
      "source": "from keras import models, layers\nfrom keras.optimizers import Adam\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D,Dropout,MaxPooling2D,Dense,Flatten\nfrom keras.layers.normalization import BatchNormalization\ntmodel_base = VGG16(weights='imagenet',include_top=False,input_shape =  t_x.shape[1:])\n\nfor layer in tmodel_base.layers[:-3]:\n    layer.trainable=False\n\ntmodel = Sequential()\ntmodel.add(tmodel_base)\ntmodel.add(Flatten())\ntmodel.add(Dense(256,activation='relu',name='start_layer'))\ntmodel.add(BatchNormalization())\ntmodel.add(Dropout(0.10))\ntmodel.add(Dense(1,activation='sigmoid',name='output_layer'))\n\ntmodel.compile(optimizer=Adam(lr=1e-2),\n              loss='binary_crossentropy',\n              metrics=['binary_accuracy'])\ntmodel.summary()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7282d18de3aff1cee12ff89b7d511a391702814f"
      },
      "cell_type": "code",
      "source": "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\nweights_dir=\"{}_weights.best.hdf5\".format('boat_detector')\n\ncheckpoint = ModelCheckpoint(weights_dir, monitor='val_loss', verbose=1, \n                             save_best_only=True, mode='min', save_weights_only = True)\n\nreduce = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=15, verbose=1, mode='auto', epsilon=0.0001, cooldown=3, min_lr=0.0001)\n\n#early = EarlyStopping(monitor=\"val_loss\", \n                     # mode=\"min\", \n                      #patience=10)\n\ncallbacks = [reduce,checkpoint]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5b67d808c0b8c7e28bff41e6d3858ff6f09dd626",
        "scrolled": false
      },
      "cell_type": "code",
      "source": "train_gen.batch_size = BATCH_SIZE\nhistory = tmodel.fit_generator(train_gen, \n                         steps_per_epoch=train_gen.n//BATCH_SIZE,\n                      validation_data=(valid_x, valid_y), \n                      epochs=30, \n                      callbacks=callbacks,\n                      workers=4)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a168c8b1af446b800f6129104906003ededd61c4"
      },
      "cell_type": "code",
      "source": "\ntmodel.load_weights(weights_dir)\ntmodel.save('tmodel_ship.h5')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "59be6cade104577ae27e3a80470a472a38afa493"
      },
      "cell_type": "code",
      "source": "plt.plot(history.history['binary_accuracy'])\nplt.plot(history.history['val_binary_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n# Plot training & validation loss values\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "35c24dfcf66b02562cae7708f038dcd5c898ce86"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "17edb177402ae51651692511827a7e9d60646533"
      },
      "cell_type": "markdown",
      "source": "## Predict the test data\nWe use the sample_submission file as the basis for loading and running the images."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4911811f267f9f3397a58902da9e75c6f261ad40"
      },
      "cell_type": "code",
      "source": "test_paths = os.listdir(test_image_dir)\nprint(len(test_paths), 'test images found')\nsubmission_df = pd.read_csv('../input/sample_submission_v2.csv')\nsubmission_df['path'] = submission_df['ImageId'].map(lambda x: os.path.join(test_image_dir, x))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f75595679ba8606fd1ac15645b8612e117db0b30"
      },
      "cell_type": "code",
      "source": "test_gen = flow_from_dataframe(valid_idg, \n                               submission_df, \n                             path_col = 'path',\n                            y_col = 'ImageId', \n                            target_size = IMG_SIZE,\n                             color_mode = 'rgb',\n                            batch_size = BATCH_SIZE, \n                              shuffle = False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b103e0ce6ccae69dbf82a55067dc693efaeadf8f"
      },
      "cell_type": "code",
      "source": "test_gen = flow_from_dataframe(valid_idg, \n                               submission_df, \n                             path_col = 'path',\n                            y_col = 'ImageId', \n                            target_size = IMG_SIZE,\n                             color_mode = 'rgb',\n                            batch_size = BATCH_SIZE, \n                              shuffle = False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0a38d343b2654f87934a88524ebc14a5759e07cb"
      },
      "cell_type": "code",
      "source": "from tqdm import tqdm_notebook\nall_scores = dict()\nfor _, (t_x, t_names) in zip(tqdm_notebook(range(test_gen.n//BATCH_SIZE+1)),\n                            test_gen):\n    t_y = ship_model.predict(t_x)[:, 0]\n    for c_id, c_score in zip(t_names, t_y):\n        all_scores[c_id] = c_score",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "4a942dbb4a939d73526dbb35745402b35785fdf4"
      },
      "cell_type": "markdown",
      "source": "### Show the Scores"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "41ab9326407f59c983f3991ff736da8dd822605c"
      },
      "cell_type": "code",
      "source": "submission_df['score'] = submission_df['ImageId'].map(lambda x: all_scores.get(x, 0))\nsubmission_df['score'].hist()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "fae5322806f03112d8110755ca48a3bdb05eeded"
      },
      "cell_type": "markdown",
      "source": "### Make the RLE data if there is a ship\nHere we make the RLE data for a positive image (assume every pixel is ship)"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "80acd5482d2a6117648a842b2f0da380bced79a5"
      },
      "cell_type": "code",
      "source": "# ref: https://www.kaggle.com/paulorzp/run-length-encode-and-decode\ndef rle_encode(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n# empty image\nzp_dim = 10\nout_img = np.ones((768-2*zp_dim, 768-2*zp_dim), dtype=bool)\nout_img = np.pad(out_img, ((zp_dim, zp_dim),), mode='constant', constant_values=0)\nplt.matshow(out_img)\nprint(out_img.shape)\npos_ship_str = rle_encode(out_img)\nprint(pos_ship_str[:50])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "580506b6e934b9a9a362deaf6b88e5d71c770405"
      },
      "cell_type": "code",
      "source": "# add the whole image if it is above the threshold\nsubmission_df['EncodedPixels'] = submission_df['score'].map(lambda x: pos_ship_str if x>0.5 else None)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b534a825f5a1997a935aa3e3f338da657024bc19"
      },
      "cell_type": "code",
      "source": "out_df = submission_df[['ImageId', 'score']]\nout_df.to_csv('submission.csv', index=False)\nout_df.head(20)",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}